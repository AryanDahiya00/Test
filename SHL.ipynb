{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5164e493-9b0c-4acf-9c8b-18120d1f33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e16a99-b443-42c8-ba8f-a6c93264fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a7677d-6eeb-44c1-b3bc-8e3de7c2124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-large-960h\").to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80b024-d8f9-4698-8796-7dea6de175cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b766483b-e365-45a3-81b7-60bd74383723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    speech, sr = torchaudio.load(file_path)\n",
    "    if speech.shape[0] > 1:\n",
    "        speech = torch.mean(speech, dim=0, keepdim=True)\n",
    "    if sr != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n",
    "        speech = resampler(speech)\n",
    "    inputs = processor(speech.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs.input_values.to(device)).last_hidden_state.squeeze(0)\n",
    "    mean_vec = outputs.mean(dim=0)\n",
    "    std_vec = outputs.std(dim=0)\n",
    "    wav2vec_feature = torch.cat([mean_vec, std_vec]).cpu().numpy()\n",
    "    mfcc_feat = librosa.feature.mfcc(y=speech.squeeze().numpy(), sr=16000, n_mfcc=40)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc_feat)\n",
    "    mfcc_delta2 = librosa.feature.delta(mfcc_feat, order=2)\n",
    "    mfcc_combined = np.concatenate([mfcc_feat, mfcc_delta, mfcc_delta2], axis=0)\n",
    "    mfcc_mean = np.mean(mfcc_combined, axis=1)\n",
    "    mfcc_std = np.std(mfcc_combined, axis=1)\n",
    "    mfcc_feature = np.concatenate([mfcc_mean, mfcc_std])\n",
    "    return np.concatenate([wav2vec_feature, mfcc_feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a334225-3e57-466c-b216-bcca1b2b0166",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = []\n",
    "for fname in train_df['filename']:\n",
    "    path = f\"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/{fname}\"\n",
    "    train_embeddings.append(extract_features(path))\n",
    "\n",
    "train_X = np.array(train_embeddings)\n",
    "train_y = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eeef8b-2893-41b1-a95e-9979cdcc1212",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.15, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de37184-df10-4776-bde1-8ff474bb5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = XGBRegressor(n_estimators=800, learning_rate=0.02, max_depth=8, subsample=0.8, colsample_bytree=0.8, random_state=42)\n",
    "model_reg.fit(X_train_scaled, y_train, eval_set=[(X_val_scaled, y_val)], early_stopping_rounds=20, verbose=False)\n",
    "\n",
    "val_preds = model_reg.predict(X_val_scaled)\n",
    "pearson = pearsonr(val_preds, y_val)[0]\n",
    "print(f\"Pearson Correlation on Validation Set: {pearson:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba9bf9-6052-49bb-9bfe-c86b75a71f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_val, y=val_preds)\n",
    "plt.xlabel(\"Actual Label\")\n",
    "plt.ylabel(\"Predicted Label\")\n",
    "plt.title(f\"Validation Pearson: {pearson:.3f}\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81f3fa1-33bd-4aa0-9191-5264f13cc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = []\n",
    "for fname in test_df['filename']:\n",
    "    path = f\"/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/{fname}\"\n",
    "    test_embeddings.append(extract_features(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1528d362-80cc-4ae9-ad85-ec985ef369d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.array(test_embeddings)\n",
    "test_X_scaled = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38a795-8d68-4502-bf8c-4821ebcd3814",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model_reg.predict(test_X_scaled)\n",
    "submission = pd.DataFrame({\n",
    "    'filename': test_df['filename'],\n",
    "    'label': test_preds\n",
    "})\n",
    "submission.to_csv('submission4_3.csv', index=False)\n",
    "print(\"Submission file created!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
